\documentclass[12pt]{article}
\input{homework.sty}
\pdfminorversion=7

\title{Homework 3}
\author{Austin Gill \\ Kali Regenold}

\begin{document}
\maketitle
\begingroup
\hypersetup{linkcolor=black}
\tableofcontents
\endgroup
\newpage

\section{Ant Clustering}

\subsection{Statement}

Use ant clustering to cluster uniformly distributed red and blue objects on a grid.
The grid should be $200 \times 200$ and there should be 100 each of red and blue objects.
Use 500 ants.

\subsection{Method}

The ant clustering algorithm is given by \autoref{alg:ant-clustering}, and is tunable by the definitions of $f$, $p_p$, $p_d$, and the paremeters $iters$, $ants$, $k_1$, and $k_2$.

\begin{algorithm}
    % \begin{noindent}
    \begin{algorithmic}
        \Function{ACA}{$iters$, $ants$, $k_1$, $k_2$}
            \State{Project items onto a 2D grid}
            \State{Randomly distribute ants in unoccupied (by another ant) locations}
            \State{$t \gets 1$}
            \While{$t < iters$}
                \For{$i \in \{1, \dots, ants\}$}\IComment{For each ant}
                    \State{Let $\vec x_i$ be the item $\vec x$ in ant $i$'s cell, if any}
                    \State{Compute $f(\vec x_i)$}
                    \IComment{$f$ is the perceived fraction of items near $\vec x_i$}
                    \If{ant $i$ is unloaded and cell contains an item}
                        \State{Compute pickup probability $p_p(\vec x_i)$}
                        \IComment{Tunable with parameter $k_1$}
                        \State{Pick up item $\vec x_i$ with probability $p_p(\vec x_i)$}
                    % The dumbest token for else if I've seen so far. Even worse then elif.
                    \ElsIf{ant $i$ is loaded and cell does not contain an item}
                        \State{Compute dropoff probability $p_d(\vec x_i)$}
                        \IComment{Tunable with parameter $k_2$}
                        \State{Drop off item $\vec x_i$ with probability $p_d(\vec x_i)$}
                    \EndIf{}
                    \State{Move ant $i$ to random unoccupied (by another ant) neighbor}
                \EndFor{}
                \State{$t \gets t + 1$}
            \EndWhile{}
            \State\Return{New locations of each item}
        \EndFunction{}
    \end{algorithmic}
    % \end{noindent}
    \caption{The standard Ant Clustering Algorithm (ACA)}\label{alg:ant-clustering}
\end{algorithm}

The pickup and dropoff probabilities are typically given by
\begin{align}
    p_p(\vec x_i) & = {\left(\frac{k_1}{k_1 + f(\vec x_i)}\right)}^2\label{eq:aca:pickup} \\
    p_d(\vec x_i) & = \begin{cases}
        2 f(\vec x_i) & \text{if} f(\vec x_i) < k_2 \\
        1             & \text{otherwise}
    \end{cases}\label{eq:aca:dropoff}
\end{align}
and the perceived fraction $f$ by
\begin{equation}
    f(\vec x_i) = \begin{cases}
        \displaystyle\frac{1}{s^2}\cdot\sum_{x_j \in \text{neighbors}}
        \left(1 - \frac{\mathrm{d}(\vec{x_i}, \vec{x_j})}{\alpha}\right) & \text{if } f > 0 \\
        0                                                                & \text{otherwise}
    \end{cases}\label{eq:aca:fraction}
\end{equation}
where the sum is over the square neighborhood of configurable size around the cell occupied by $\vec{x_i}$.
The parameter $\alpha$ is a tunable parameter that determines the scale of dissimilarity, and the distance metric $\mathrm d(\vec x, \vec y)$ is the Euclidean distance \textit{in the original, unprojected, space}.
For this problem though, we are starting with uniformly distributed points already in 2 dimensions.
\footnote{This is uncommon for ant clustering algorithms, but is suitable for a homework problem because the process of performing the projection from a possibly very high dimensional space to 2 dimensions is nontrivial.
    Especially so if the projection should retain certain characteristics of the original space.

    My current understanding though, is that even a randomish projection, or a naive application of a dimension reduction technique like PCA is fine, because the perceived fraction $f$ uses the distance metric $\mathrm{d}(\vec x, \vec y)$ in the original space, and it should be possible to project the found clusters in 2 dimensions back into the original space.}

However, it seems this definition is nonintuitively recursive, we believe the intent of \autoref{eq:aca:fraction} is that shown in \autoref{eq:aca:fraction-max}.

\begin{equation}
    f(\vec x_i) = \displaystyle\max\left(\frac{1}{s^2}\cdot\sum_{x_j \in \text{neighbors}}
    \left(1 - \frac{\mathrm{d}(\vec{x_i}, \vec{x_j})}{\alpha}\right), 0 \right)\label{eq:aca:fraction-max}
\end{equation}

Regardless, since the clustering is being performed in the same space as the objects, it is possible to use a better perceived fraction function.

\begin{equation}
    f(\vec x_i) = \frac{1}{s^2}\cdot\sum_{x_j \in \text{neighbors}}\bigg(\mathrm{type}(x_i) = \mathrm{type}(x_j)\bigg)\label{eq:aca:density}
\end{equation}

That is, to count the number of objects in the neighborhood (of configurable size) around $\vec x_i$ with the same type as $\vec x_i$.
Note that this density function is normalized by the size of the neighborhood as well.
This was important, because we wanted to play with as many tweakable parameters as possible --- the neighborhood size being one of those parameters.

\subsection{Implementation}

\subsubsection{The Grid}
The grid is a \(n \times m \times 2\) numpy array.
The colored objects are placed randomly on the 0\textsuperscript{th} layer and ant indicators for each grid cell are stored in the the 1\textsuperscript{st} layer.
The most of the implementation of the actual algorithm is left to each ant, so the grid mostly facilitates information passing and batch instructions.

\begin{minted}{python}
    def init_grid(self):
        """Get a randomly initialized grid of objects."""
        num_objects = sum(self.colors)
        assert (
            num_objects <= self.width * self.height
        ), "Too many colored objects to fit in the grid."
        # Use 1D arrays because that's all I can generate random indices for.
        object_grid = np.zeros((self.height * self.width, 2), dtype=int)
        random_indices = np.random.choice(self.height * self.width, num_objects, replace=False)

        start = 0
        # 0 represents unoccupied, so start color indexing at 1.
        for color, num_color in enumerate(self.colors, start=1):
            object_grid[random_indices[start : start + num_color], 0] = color
            start += num_color

        self.grid = object_grid.reshape((self.width, self.height, 2))
\end{minted}

When an ant picks up an item from the grid, it removes it entirely, rather than setting a flag that indicates that object is being carried, or moving the item through the grid cells as the ant walks around.
We had several reasons for making this implementation decision.
\begin{itemize}
    \item In our first iteration --- a particular ant had no knowledge of surrounding ants, so it was quite impossible to prevent it from occupying the same cell as another ant.
          This resulted in items being clobbered when multiple ants moved their objects to the same cell.
    \item In our second iteration --- once ants were able to see other ants, objects being carried were still considered in the implementation of the \mintinline{python}{perceived_fraction()} function.

          At first we thought this was acceptable, but testing revealed that \textit{no} clusters were being formed. As soon as we removed items from the grid once an ant picked them up we saw distinct clusters forming almost immediately.
\end{itemize}

In certain cases where the number of ants is larger than the number of objects in a proportionally small area, the ants can pick up all the objects and never drop any off.
We implemented a workaround for this case where it periodically forces all ants to drop what they have.
Algorithmically, this is like a reset to the algorithm where the initial grid is in an almost clustered state.
Biologically, this is like the ants having short term memory.

Further testing revealed that tuning the dropoff probabilities and running the algorithm for more iterations had a much better impact than forcing every ant to drop their objects every so often.

\subsubsection{The Ants}
The ants are implemented as a list of ant objects (much to the dismay of one of the authors).
We decided to give the ants individual control over their location\footnote{An observant reader would notice that we now have two places where the ants' location is stored---once as a indicator on the grid and once as the \mintinline{python}{x} and \mintinline{python}{y} values in the \mintinline{python}{Ant} class. Software engineers all over the world cringe in unison.} so the nature of the ACA (where the unintelligent individuals create an intelligent algorithm) can be plainly seen.
It also vastly simplified the implementation of the algorithm to the point where the outermost loop almost reads \mintinline{python}{[ant.update() for ant in self.ants]}.

The \mintinline{python}{update_load()} function is the heart of the ACA, and closely mimics \autoref{alg:ant-clustering}.

\begin{minted}{python}
    def update_load(self, kernel, k_x, k_y):
        """Randomly pick up or drop off an object."""
        color = kernel[k_x, k_y, 0]
        cell_occupied = bool(color)

        # Pick up
        if self.load == EMPTY and cell_occupied:
            f = self.perceived_fraction(kernel[:, :, 0], color)
            if np.random.random() <= self.pickup_probability(f):
                self.pickup(kernel, k_x, k_y)
        # Drop off
        elif self.load != EMPTY and not cell_occupied:
            f = self.perceived_fraction(kernel[:, :, 0], self.load)
            if np.random.random() <= self.dropoff_probability(f):
                self.dropoff(kernel, k_x, k_y)
\end{minted}

The ants can move to any unoccupied cell in their viewing radius.
When the radius is 1, this operates like normal single-step-in-any-direction motion.
Anything larger than 1 and the ant can ``teleport'' to a nearby location.\footnote{Fixing the code to only let the ant move adjacent to itself broke everything in completely unexpected ways, so we gently put it back and walked away.}
Since this creates some pretty quick ants, it is best to keep the viewing radius to 3 or lower.

\subsubsection{Tunable Parameters}

We implemented the ability to turn all the knobs and spin all the dials via commandline arguments.
The tunable parameters come in two flavors --- the problem size and configuration --- and runtime parameters.

\begin{minted}{text}
    $ ./prob1.py --help
    usage: prob1.py [-h] [--width WIDTH] [--height HEIGHT] [--ants ANTS]
                    [--iterations ITERATIONS] [--radius RADIUS] [--k1 K1]
                    [--k2 K2] [--reset-period RESET_PERIOD] [--animate]
                    [--colors COLORS [COLORS ...]] [--headless]

    Cluster objects with Ants.

    optional arguments:
      -h, --help            show this help message and exit
      --width WIDTH, -x WIDTH
                            The width of the grid to cluster.
      --height HEIGHT, -y HEIGHT
                            The height of the grid to cluster.
      --ants ANTS, -s ANTS  The number of ants to use.
      --iterations ITERATIONS, -i ITERATIONS
                            The number of iterations to run.
      --radius RADIUS       The ant's perceiveable radius.
      --k1 K1               The k1 tunable parameter
      --k2 K2               The k2 tunable parameter
      --reset-period RESET_PERIOD, -p RESET_PERIOD
                            Force ants to drop off their items every P iterations.
                            -1 to disable.
      --animate, -a         Animate the clustering progress.
      --colors COLORS [COLORS ...]
                            The number of objects to use for each color.
      --headless            Run in headless mode for profiling.
\end{minted}

The size of the grid, number of colors, number of objects of each color, and the number of ants are configurable, as well as the ant's perceptive radius, proportionally constants, and whether to force ants to drop their loads periodically are configurable as well.

\subsubsection{Just-In-Time Compilation}
One of the things we wanted to do from the get-go was to use the \mintinline{python}{numba} library to Just-In-Time (JIT) compile our code.
The Numba literature seemed to indicate that a simple one line addition to each performance critical function would magically make things faster.
This is partially true.

Numba has several limitations, the must infuriating of which is that it cannot JIT compile a class instance method.
This makes sense if you consider the Python type system and function decorators.
It is not possible for a decorator to know at compile-time the type of the \mintinline{python}{self} parameter implicitly passed to each instance method.

More surprising however, is that the Numba \mintinline{python}{@njit} decorator will not compile static class methods decorated with \mintinline{python}{@staticmethod}.
This means that any function you wish to JIT compile must be a free function with fairly rigid types on each of its parameters.

For example, we JIT compiled the following methods
\begin{minted}{python}
    @staticmethod
    def __kernel(matrix, x1, y1, x2, y2):
        """Get the kernel from (x1, y1) to (x2, y2) from the given matrix."""
        # Only get the first two dimensions of the matrix if more exist.
        width, height = matrix.shape[:2]
        x1 = max(0, min(x1, width))
        x2 = max(0, min(x2, width))
        y1 = max(0, min(y1, height))
        y2 = max(0, min(y2, height))
        return matrix[x1 : x2 + 1, y1 : y2 + 1]

    @classmethod
    def kernel_center(cls, matrix, x, y, r):
        """Get the kernel centered at (x, y) with radius `r` from the given matrix."""
        x1, x2 = x - r, x + r
        y1, y2 = y - r, y + r
        return cls.__kernel(matrix, x1, y1, x2, y2)

    @staticmethod
    def kernel_coords(coords, radius):
        """Given a set of matrix coordinates and a kernel radius, get the local kernel coordinates."""
        x, y = coords
        return min(radius, x), min(radius, y)
\end{minted}

like so:

\begin{minted}{python}
    @numba.jit(nopython=True, cache=True)
    def __kernel(matrix, x1, y1, x2, y2):
        """Get the kernel from (x1, y1) to (x2, y2) from the given matrix."""
        # Only get the first two dimensions of the matrix if more exist.
        width, height = matrix.shape[:2]
        x1 = max(0, min(x1, width))
        x2 = max(0, min(x2, width))
        y1 = max(0, min(y1, height))
        y2 = max(0, min(y2, height))
        return matrix[x1 : x2 + 1, y1 : y2 + 1]

    @numba.jit(nopython=True, cache=True)
    def kernel_center(matrix, x, y, r):
        """Get the kernel centered at (x, y) with radius `r` from the given matrix."""
        x1, x2 = x - r, x + r
        y1, y2 = y - r, y + r
        return __kernel(matrix, x1, y1, x2, y2)

    @numba.jit(nopython=True, cache=True)
    def kernel_coords(coords, radius):
        """Given a set of matrix coordinates and a kernel radius, get the local kernel coordinates."""
        x, y = coords
        return min(radius, x), min(radius, y)
\end{minted}

We can see that the implementation of the functions did not differ, only the scope in which they are defined, and the lack of \mintinline{python}{@decorator}s applied at their definitions.

However, as neat as this is, it had little-to-no impact on the program runtime.
Profiling revealed that it was the methods in the \mintinline{python}{Ant} class that were the biggest contributors to the runtime.

Unfortunately, JIT compiling an entire class, while possible with the \mintinline{python}{@numba.jitclass} decorator, is more troublesome.
As mentioned, it is not possible to compile an instance method, bit it \textit{is} possible to compile the whole class, including the instance methods.
Unfortunately, doing so requires \textit{every} instance method to be compiled, and not just the ones that meaningfully impact the runtime.

For simple classes, performing this JIT compilation is quite easy --- you provide a map of instance attributes and their types to the compiler, and it magically does everything else for you.
Unfortunately\footnote{I think ``unfortunately'' might be becoming my favorite word. There's just something poetic about getting one's hopes up only to dash them to the ground repeatedly.} this breaks as soon as one of the attributes is a non-basic type --- say an instance of another class, or something Python specific.

In our case, the \mintinline{python}{Ant} class contains only basic types and methods that operate on them, so the only change we had to make was to add the type specification shown below.

\begin{minted}{python}
    spec = [
        ("x", numba.int32),
        ("y", numba.int32),
        ("k1", numba.float32),
        ("k2", numba.float32),
        ("load", numba.int32),
    ]

    @numba.jitclass(spec)
    class Ant:
        """An ant entity that moves around and picks up and puts down objects."""

        def __init__(self, x, y, k1, k2):
            """Initialize an Ant with its location and tunable parameters.

            :param x: The x coordinate of the Ant in the grid.
            :param y: The y coordinate of the Ant in the grid.
            :param k1: The pickup probability tunable parameter.
            :param k2: The dropoff probability tunable parameter.
            """
            self.x = x
            self.y = y
            self.k1 = k1
            self.k2 = k2
            self.load = EMPTY
\end{minted}

That and we had to change the \mintinline{python}{perceived_fraction()} function from
\begin{minted}{python}
    def perceived_fraction(self, kernel, color):
        """Determine the perceived fraction of objects of a given color around the given kernel."""
        return np.count_nonzero(kernel == color) / kernel.size
\end{minted}
to
\begin{minted}{python}
    def perceived_fraction(self, kernel, color):
        """Determine the perceived fraction of objects of a given color around the given kernel."""
        return np.sum(kernel == color) / kernel.size
\end{minted}
because apparently \mintinline{python}{numpy.count_nonzero()} is complicated enough to warrant Numba not supporting it despite the wild claims to the contrary their documentation makes.

After spending about 8 hours wrestling with compilation warning messages second only to those a grouchy \LaTeX{} compiler makes, we were able to cut our runtime in half.
That's right, we saved a whopping 15 seconds with every run, at the cost of 8 hours of development work and $\sim 5$ seconds of compilation with every run because \mintinline{python}{@numba.jitclass} can't cache its results like \mintinline{python}{@numba.njit} can.\footnote{There were also brain cells lost as well, but not due to the painful experience of compiling a language not meant for compilation. Those brain cells were lost due to a more\dots liquid factor.}

\subsection{Results}
As mentioned, there are many tweakable parameters for this problem. Here, we will explore the most impactful parameters, but will do so on a smaller grid for ease of computation and interpretation.\footnote{As well as making the images small enough to display while big enough to see individual pixels.}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/aca/aca-w100-h100-o100-c2-a500-r1-k10_1-k20_1.eps}
    \caption{Initial random distribution of 100 objects on a $100 \times 100$ grid.}\label{fig:aca:rand-objects}
\end{figure}

\subsubsection{Number of Ants}
The most obvious parameter to tweak is the number of ants.

\begin{figure}[H]
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o100-c2-a50-r1-k10_1-k20_1.eps}
        \caption{Clustering with 50 ants}\label{fig:aca:num-ants-50}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o100-c2-a100-r1-k10_1-k20_1.eps}
        \caption{Clustering with 100 ants}\label{fig:aca:num-ants-100}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o100-c2-a500-r1-k10_1-k20_1.eps}
        \caption{Clustering with 500 ants}\label{fig:aca:num-ants-200}
    \end{subfigure}
    \caption{The impact of the number of ants}\label{fig:aca:num-ants}
\end{figure}

\subsubsection{Ant Perceptive Distance}
As mentioned, we implemented the ability to increase each ant's perceptive range by increasing the radius of the neighborhood around them when calculating the perceived fraction $f$ from \autoref{eq:aca:density}.
What we expected was to see an increase in the cluster size, which did happen occasionally.
Sometimes, the ants would cluster one color, and then pick up and hold the rest of the objects and never put them down.\footnote{I guess this is actually a success if what you're interested in is an unsupervised classifier --- it has made two classifications. Things that have a cluster and things that don't.}

\begin{figure}[H]
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o100-c2-a100-r1-k10_1-k20_1.eps}
        \caption{Clusters with radius 1}\label{fig:aca:radius-1}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o100-c2-a100-r2-k10_1-k20_1.eps}
        \caption{Clusters with radius 2}\label{fig:aca:radius-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o100-c2-a100-r3-k10_1-k20_1.eps}
        \caption{Clusters with radius 3}\label{fig:aca:radius-3}
    \end{subfigure}
    \caption{The impact of different radii}\label{fig:aca:radius}
\end{figure}

Notice that the clusters get more spread out as the perceptive radius increases.
This is expected, because the ant can drop off items further and further from objects as its perceptive radius increases.

Also notice that as the radius increases, more and more objects are not placed into a cluster. Tuning the dropoff probability via $k_2$, and increasing the number of iterations fixes this.

\subsubsection{The Proportionality Constants $k_1$ and $k_2$}
\begin{figure}[H]
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/k1-r1.eps}
        \caption{$k_1$ vs neighbors with $r=1$}
    \end{subfigure}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/k1-r2.eps}
        \caption{$k_1$ vs neighbors with $r=2$}
    \end{subfigure}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/k1-r3.eps}
        \caption{$k_1$ vs neighbors with $r=3$}
    \end{subfigure}

    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/k2-r1.eps}
        \caption{$k_2$ vs neighbors with $r=1$}
    \end{subfigure}%
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/k2-r2.eps}
        \caption{$k_2$ vs neighbors with $r=2$}
    \end{subfigure}%
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/k2-r3.eps}
        \caption{$k_2$ vs neighbors with $r=3$}
    \end{subfigure}
    \caption{The impact of $k_1$ and $k_2$ on the pickup and dropoff probabilities}\label{fig:aca:k1-k2}
\end{figure}

From \autoref{fig:aca:k1-k2} we can see that
\begin{enumerate}
    \item Increasing $k_1$ makes it more likely to pick up an object.
    \item Decreasing $k_2$ makes it more likely to drop off an object.
\end{enumerate}

In discussion with other classmates, I was led to believe that the probability functions would have to be tweaked to get similar curves once the neighborhood radius is increased.
This is in fact not true.
Due to the manner in which we normalized \autoref{eq:aca:density} by the neighborhood size, the only impact increasing the neighborhood size has is making the curves smoother.
This makes sense, because as the number of surrounding cells increase, there are more and more datapoints to interpolate between, but the magnitudes involved remain bounded.

While the probability plots for $k_2$ make sense after some though, it doesn't quite make sense to us why the dropoff probability function is piecewise.
It is a simple matter to get an upside-down version of the $k_1$ curves.

\subsubsection{The Number of Colors}
One of the things we implemented was the ability to have an arbitrary number of colors.\footnote{As long as that number of colors is less than 8 due to the difficulty of customizing \mintinline{python}{matplotlib} colormaps. The color maps were meant for describing the color scale of a continuous range of values, with the given colors being the points to interpolate between.

    Well, if you have $n$ datapoints, and $n$ points to interpolate between, the interpolated colors will be the colors you specified. The downside of this nifty little implementation detail is that it's decidedly gross.}

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o100-c2-a100-r1-k10_1-k20_1-i4000.eps}
        \caption{Clustering with 2 colors}\label{fig:aca:colors-2}
    \end{subfigure}%
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o150-c3-a150-r1-k10_1-k20_1.eps}
        \caption{Clustering with 3 colors}\label{fig:aca:colors-3}
    \end{subfigure}%

    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o200-c4-a200-r1-k10_1-k20_1.eps}
        \caption{Clustering with 4 colors}\label{fig:aca:colors-4}
    \end{subfigure}%
    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o250-c5-a200-r1-k10_1-k20_1.eps}
        \caption{Clustering with 5 colors}\label{fig:aca:colors-5}
    \end{subfigure}
    \caption{Results with different numbers of colors}\label{fig:aca:colors}
\end{figure}

We can see that the performance of the ACA algorithm apparently doesn't care about the number of type of objects being clustered.
This is apparent from the pseudocode given in \autoref{alg:ant-clustering} --- which makes no mention whatsoever about the discrete types of objects being clustered.
In fact, the algorithm is intended to work on data without distinct classifications --- the point is to learn the classifications from an unlabeled dataset.
It may be that there are no categorical variables in the dataset.

The magic is entirely within the perceived density function given in \autoref{eq:aca:density}.
That is where handling continuous variables would be handled if there were any.

This is not an algorithm that will work off-the-shelf for most datasets.
It involves some tuning, and if our experience is any indication, a fair amount of frustration at the seemingly idiotic behavior of mindless insects.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/aca/aca-w100-h100-o350-c7-a300-r1-k10_1-k20_1.eps}
    \caption{Clusters of 7 colors}\label{fig:aca:colors-7}
\end{figure}
\subsubsection{The Number of Objects}
We can also play with the number of objects, holding all other parameters constant, to get a feel for how the ACA algorithm behaves.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o50-c2-a300-r2-k10_1-k20_1.eps}
        \caption{Clusters with 25 of each color}\label{fig:aca:numbers-25}
    \end{subfigure}%
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o100-c2-a300-r2-k10_1-k20_1.eps}
        \caption{Clusters with 50 of each color}\label{fig:aca:numbers-50}
    \end{subfigure}%

    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o200-c2-a300-r2-k10_1-k20_1.eps}
        \caption{Clusters with 100 of each color}\label{fig:aca:numbers-100}
    \end{subfigure}%
    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w100-h100-o400-c2-a300-r2-k10_1-k20_1.eps}
        \caption{Clusters with 200 of each color}\label{fig:aca:numbers-200}
    \end{subfigure}
    \caption{Clustering results with 300 ants and a radius of 2}\label{fig:aca:numbers}
\end{figure}

\autoref{figL:aca:numbers} shows the results of the ACA algorithm using 300 ants, each with a perceived radius of 2.
From this we can learn several things.

First, the number of ants is important to consider.
If there are too many ants, they might pick up all the objects before any clusters can form.

Second, as the number of objects increases, there are more objects laying around,\footnote{Here's your tautology for the day.} so it is more likely for an ant to encounter items the same type as the one it is carrying, so the clusters get better and better.

\subsection{Conclusion}
Returning to the prescribed problem size, here are our recommendations for the tunable parameters.

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w200-h200-o200-c2-a500-r2-k10_1-k20_02.eps}
        \caption{Clusters with $r=2$ and $k_2 = 0.02$}\label{fig:aca:prob-r2-k2-02}
    \end{subfigure}%
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w200-h200-o200-c2-a500-r2-k10_1-k20_05.eps}
        \caption{Clusters with $r=2$ and $k_2 = 0.05$}\label{fig:aca:prob-r2-k2-05}
    \end{subfigure}%

    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w200-h200-o200-c2-a500-r3-k10_1-k20_02.eps}
        \caption{Clusters with $r=3$ and $k_2 = 0.02$}\label{fig:aca:prob-r3-k2-02}
    \end{subfigure}%
    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w200-h200-o200-c2-a500-r3-k10_1-k20_05.eps}
        \caption{Clusters with $r=3$ and $k_2 = 0.05$}\label{fig:aca:prob-r3-k2-05}
    \end{subfigure}%
    \caption{Clustering results with different radii and $k_2$ values}\label{fig:aca:prob-radii-k2}
\end{figure}

We recommend using larger ranges for the ant perception.
As \autoref{fig:aca:prob-radii-k2} shows, we had decent results when we increased the ant neighborhood radius to 2 or 3, and used small values for $k_2$.
Using $k_2 = 0.02$ resulted in very few unclustered items at the end of 8000 iterations.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w200-h200-o200-c2-a500-r2-k10_05-k20_02.eps}
        \caption{Clusters with $r=2$ and $k_1 = 0.05$}\label{fig:aca:prob-r2-k1-05}
    \end{subfigure}%
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w200-h200-o200-c2-a500-r2-k10_15-k20_02.eps}
        \caption{Clusters with $r=2$ and $k_1 = 0.15$}\label{fig:aca:prob-r2-k1-15}
    \end{subfigure}%

    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w200-h200-o200-c2-a500-r3-k10_05-k20_02.eps}
        \caption{Clusters with $r=3$ and $k_1 = 0.05$}\label{fig:aca:prob-r3-k1-05}
    \end{subfigure}%
    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aca/aca-w200-h200-o200-c2-a500-r3-k10_15-k20_02.eps}
        \caption{Clusters with $r=3$ and $k_1 = 0.15$}\label{fig:aca:prob-r3-k1-15}
    \end{subfigure}%
    \caption{Clustering results with different radii and $k_1$ values}\label{fig:aca:prob-radii-k1}
\end{figure}

After having set $k_2 = 0.02$ satisfactorily, we then played around with different values for $k_1$.
\autoref{fig:aca:prob-radii-k1} shows that pushing $k_1$ to either side of the default $0.1$ value had far less impact than tuning $k_2$.
\clearpage
\section{Particle Swarm Optimization}

\subsection{Statement}

Use particle swarm optimization to optimize the function
\begin{equation}
    f(x) = 2^{-2{\left(\frac{(x - 0.1)}{0.9}\right)}^2}{\big(\sin(5\pi x)\big)}^6\label{eq:pso:objective}
\end{equation}
and compare the results with those of simulated annealing from Homework 1.
\begin{figure}
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/pso/prob1-function.eps}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/pso/prob1-derivative.eps}
    \end{subfigure}
    \caption{The objective function~\ref{eq:pso:objective} and its derivative.}\label{fig:pso:objective}
\end{figure}
\autoref{eq:pso:objective} is plotted, along with its derivative, in \autoref{fig:pso:objective}.

\subsection{Method}

The standard particle swarm algorithm from the book is given in \autoref{alg:particle-swarm}.
The algorithm is tunable by the number of iterations, the acceleration constants $AC_1$ and $AC_2$, and the range of allowable velocities $[v_{\min}, v_{\max}]$.

\begin{algorithm}
    % \begin{noindent}
    \begin{algorithmic}
        \Function{PS}{$iters$, $AC_1$, $AC_2$, $v_{\min}$, $v_{\max}$}
            \State{Randomly initialize swarm $\vec{x_i} \in X$}
            \State{Randomly initialize swarm velocities $\Delta\vec{x_i}$}
            \IComment{$\Delta\vec{x_i} \in [v_{\min}, v_{\max}]$}
            \State{Let each $\vec{p_i} \gets \vec{x_i}$}
            \IComment{Best historical position for each particle}
            \State{$t \gets 1$}
            \While{$t < iters$}
                \For{$i \in \{1, \dots, particles\}$}
                    \IComment{For each particle}
                    \If{$f(\vec{x_i}) > f(\vec{p_i})$}
                        \IComment{Keep track of each particle's best position}
                        \State{$\vec{p_i} \gets \vec{x_i}$}
                    \EndIf{}
                    \State{$k \gets i$}\IComment{Arbitrary starting index}
                    \For{$j \in \{\text{neighbors of $\vec{x_i}$}\}$}
                        \IComment{Keep track of each particle's best neighbor}
                        \If{$f(\vec{p_j}) > g(\vec{p_k})$}
                            \State{$k \gets j$}
                        \EndIf{}
                    \EndFor{}
                    \State{Generate $\vec{\varphi_1}$ and $\vec{\varphi_2}$ uniformly}
                    \IComment{elementwise $\vec\varphi_i \in [0, AC]$}
                    % TODO: There's got to be a way to left justify the comment with the following
                    % line's indentation when it appears on an empty line...
                    \Statex\IComment{Linear combination of particle $i$'s historical best and neighbor's best}
                    \State{$\Delta\vec{x_i} \gets \Delta\vec{x_i} + \vec{\varphi_1} \otimes (\vec{p_i} - \vec{x_i}) + \vec{\varphi_2} \otimes (\vec{p_k} - \vec{x_i})$}
                    \State{$\Delta\vec{x_i} \in [v_{\min}, v_{\max}]$}
                    \IComment{Do not allow the velocities to explode, componentwise}
                    \State{$\vec{x_i} \gets \vec{x_i} + \Delta\vec{x_i}$}
                \EndFor{}
                \State{$t \gets t + 1$}
            \EndWhile{}
            \State\Return{$X$}
        \EndFunction{}
    \end{algorithmic}
    % \end{noindent}
    \caption{The standard Particle Swarm (PS) optimization algorithm}\label{alg:particle-swarm}
\end{algorithm}

The book states that the acceleration constants should equal 4.1. That is,
\[AC_1 + AC_2 = 4.1\]
with $AC_1 = AC_2 = 2.05$.
The acceleration constants are used to draw the vectors of weights $\vec{\varphi_1}$ and $\vec{\varphi_2}$ from a uniform distribution of $[0, AC_1]$ and $[0, AC_2]$ respectively.
Note that the $\otimes$ symbol is elementwise multiplication.

The update step
\begin{equation}
    \Delta\vec{x_i} \gets \Delta\vec{x_i} + \vec{\varphi_1} \otimes (\vec{p_i} - \vec{x_i}) + \vec{\varphi_2} \otimes (\vec{p_k} - \vec{x_i})\label{eq:pso:update}
\end{equation}
considers the direction towards the particle's best known position, and the best known position of its neighbors.
It updates its velocity as a randomly weighted linear combination of those directions.

There are several variants of \autoref{alg:particle-swarm} to consider.
One such variation is to consider, not the each best historical position of each particle's neighbors, but the best historical position of the entire swarm.
This difference is shown in \autoref{alg:particle-swarm-variant}.

\begin{algorithm}
    % \begin{noindent}
    \begin{algorithmic}
        \Function{PS-variant}{$iters$, $AC_1$, $AC_2$, $v_{\min}$, $v_{\max}$}
            \State{Randomly initialize swarm $\vec{x_i} \in X$}
            \State{Randomly initialize swarm velocities $\Delta\vec{x_i}$}
            \IComment{$\Delta\vec{x_i} \in [v_{\min}, v_{\max}]$}
            \State{Let each $\vec{p_i} \gets \vec{x_i}$}
            \IComment{Best historical position for each particle}
            \State{Let $\vec{p} \gets$ best $\vec{x_i} \in X$}
            \IComment{Swarm's best historical position}
            \State{$t \gets 1$}
            \While{$t < iters$}
                \For{$i \in \{1, \dots, particles\}$}
                    \IComment{For each particle}
                    \If{$f(\vec{x_i}) > f(\vec{p_i})$}
                        \IComment{Keep track of each particle's best position}
                        \State{$\vec{p_i} \gets \vec{x_i}$}
                    \EndIf{}
                    \If{$f(\vec{x_i}) > f(\vec{p})$}
                        \IComment{Update the swarm's best position}
                        \State{$\vec{p} \gets \vec{x_i}$}
                    \EndIf{}
                    \State{Generate $\vec{\varphi_1}$ and $\vec{\varphi_2}$ uniformly}
                    \IComment{elementwise $\vec\varphi_i \in [0, AC]$}
                    % TODO: There's got to be a way to left justify the comment with the following
                    % line's indentation when it appears on an empty line...
                    \Statex\IComment{Linear combination of particle $i$'s historical best and
                        swarm's best}
                    \State{$\Delta\vec{x_i} \gets \Delta\vec{x_i} + \vec{\varphi_1} \otimes (\vec{p_i} - \vec{x_i}) + \vec{\varphi_2} \otimes (\vec{p} - \vec{x_i})$}
                    \State{$\Delta\vec{x_i} \in [v_{\min}, v_{\max}]$}
                    \IComment{Do not allow the velocities to explode, componentwise}
                    \State{$\vec{x_i} \gets \vec{x_i} + \Delta\vec{x_i}$}
                \EndFor{}
                \State{$t \gets t + 1$}
            \EndWhile{}
            \State\Return{$X$}
        \EndFunction{}
    \end{algorithmic}
    % \end{noindent}
    \caption{A variant Particle Swarm optimization algorithm}\label{alg:particle-swarm-variant}
\end{algorithm}

We implemented \autoref{alg:particle-swarm-variant} to solve the given problem.

\subsection{Implementation}

The implementation of a single iteration of \autoref{alg:particle-swarm-variant} is straightforward.

\begin{minted}{python}
    def update(self, func):
        """Perform one iteration of optimization."""
        for i, particle in enumerate(self.particles):
            if func(x) > func(self.history[i]):
                self.history[i] = particle
            if func(x) > func(self.best):
                self.best = particle

            phi1 = np.random.uniform(low=0, high=self.AC1, size=1)
            phi2 = np.random.uniform(low=0, high=self.AC2, size=1)

            self.velocities[i] += phi1 * (self.history[i] - particle) + phi2 * (self.best - particle)
            # Clip the velocities.
            self.velocities[i] = min(self.vmax, max(self.vmin, self.velocities[i]))
            self.particles[i] += self.velocities[i]
            # Clip the positions.
            self.particles[i] = min(self.xmax, max(self.xmin, self.particles[i]))
\end{minted}

It \textit{should} be straightforward to parallelize this to update each particle at once, or in batches.
However, to do so correctly, the swarm's best known position, \mintinline{python}{self.best} should be guarded with a mutex.
Further, multithreading in Python often yields little-to-no improvement in runtime, because every single object in Python is guarded by the Global Interpreter Lock (GIL).
Threading is still useful in networking or file operation contexts, threading is eschewed for performing CPU-bound work in favor of multiprocessing.
The difficulty in using multiple processes for this task is that they have no shared memory, which increases the amount of communication overhead to a point we are unlikely to see a big performance benefit for this particular problem.

Not to mention that extremely small numbers of particles were still effective in optimizing \autoref{eq:pso:objective} due to the size of the feasible region.

Note that this implementation is strictly one-dimensional.
Additional work must be done to optimize functions of multiple variables.
To work in more than one dimension,
\begin{itemize}
    \item $\varphi_1$ and $\varphi_2$ should have the same dimension as each particle.
    \item Each particle velocity should be a tuple of velocities --- one for each dimension.
    \item The particle velocity and position clipping should be done componentwise.
\end{itemize}

Running the PSO algorithm for multiple iterations is equally straightforward.

\begin{minted}{python}
    def optimize(self, func, iters, animate=False):
        """Optimize the given function for `iters` iterations."""
        b = np.argmax(func(self.particles))
        self.best = self.particles[b]

        for i in range(iters):
            self.update(func)

            if animate and i % 5 == 0:
                self.plot(func, blocking=False)

        return self.best
\end{minted}

As in the first problem, we implemented our solution in such as way as to allow us to play with a large number of tweakable parameters.
All of the parameters are adjustable via commandline arguments shown below.

\begin{minted}{text}
    $ ./prob2.py --help
    usage: prob2.py [-h] [--xmin XMIN] [--xmax XMAX] [--ac1 AC1] [--ac2 AC2]
                    [--vmin VMIN] [--vmax VMAX] [--particles PARTICLES]
                    [--iterations ITERATIONS] [--animate] [--headless]

    Optimize a function with a particle swarm.

    optional arguments:
    -h, --help              show this help message and exit
    --xmin XMIN             The lower domain boundary.
    --xmax XMAX             The upper domain boundary.
    --ac1 AC1               Acceleration constant for the particle history component.
    --ac2 AC2               Acceleration constant for the swarm history component.
    --vmin VMIN             The particle velocity lower bound.
    --vmax VMAX             The particle velocity upper bound.
    --particles PARTICLES, -p PARTICLES
                            The number of particles in the swarm.
    --iterations ITERATIONS, -i ITERATIONS
                            The number of iterations to use.
    --animate               Animate the swarm's progress.
    --headless              A headless mode for profiling.
\end{minted}

Note that considerable more work would need to be done, as above, to make this wrapper script handle multivariate objective functions.
The difficulty lies in specifying the feasible region to optimize over, using commandline arguments.

Setting the objective function to optimize is less easy to do from the commandline,\footnote{In a secure fashion. It's possible to use \mintinline{python}{eval()} or \mintinline{python}{ast.literal_eval()}, but both of these methods make this author queasy.}
so the \mintinline{python}{func(x)} function in the `prob2.py' script must be edited.

\subsection{Results}
\subsubsection{Hill Climbing}
Recall\footnote{Or let us make the recollection for you.} from Homework 1 that hill climbing struggles with ``spiky'' functions.
\autoref{fig:pso:hill-climbing-results} shows the results from several independent runs of the hill climbing algorithm on the objective function \autoref{eq:pso:objective}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/prob1-hill-climbing-results.eps}
    \caption{Results from three successive runs of the hill climbing algorithm.}\label{fig:pso:hill-climbing-results}
\end{figure}

Running the randomly-initialized hill climbing algorithm multiple times in parallel and taking the best result works okay, as long as the number of parallel runs is proportional to the density of the spikes in the feasible region.
\autoref{fig:pso:hill-climbing-parallel} shows the aggregated results of several parallel runs of the iterated hill climbing algorithm.

From this we can immediately see that there is quite a bit in the variance of multiple runs.
The success of the hill climbing algorithm depends entirely on the its random initialization.

\begin{figure}[H]
    \centering
    \includegraphics{figures/pso/prob1-hill-climbing-solution.eps}
    \caption{Results from multiple runs of the hill climbing algorithm in parallel.}\label{fig:pso:hill-climbing-parallel}
\end{figure}

\subsubsection{Simulated Annealing}
Recall also that simulated annealing worked \textit{much} better.
\autoref{fig:pso:simulated-annealing-results} shows a steady peak-to-peak trend from the simulated annealing algorithm, because it accepts enough random solutions to explore non-local space, but over time cools down enough to settle to a reasonable solution.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/prob1-simulated-annealing-results.eps}
    \caption{Results from three successive runs of the simulated annealing algorithm.}\label{fig:pso:simulated-annealing-results}
\end{figure}

\autoref{fig:pso:simulated-annealing-parallel} is much more illuminating; not only does the simulated annealing algorithm not find non-global solutions, each iterated run settled down to exactly the same solution.

\begin{figure}[H]
    \centering
    \includegraphics{figures/pso/prob1-simulated-annealing-solutions.eps}
    \caption{Results from multiple runs of the simulated annealing algorithm in parallel.}\label{fig:pso:simulated-annealing-parallel}
\end{figure}

\subsubsection{Particle Swarm}
As mentioned above, we enabled the modification of multiple different tweakable parameters via commandline arguments.
Below we discuss the impacts of several such parameters.

We arbitrarily chose default parameters, and as mentioned below, we can get much better performance by applying some amount of intelligence.

\paragraph{The Swarm Size} The easiest and most obvious parameter to tweak for the particle swarm algorithm is the number of particles to use.
With our poorly chosen default parameters, simply increasing the number of particles was sufficient to guarantee convergence to the solution.

This is an acceptable method due to the size and complexity of the problem.
We are optimizing a well-behaved univariate function over a small feasible region with a relatively small number of spikes.
All the swarm needs to do to converge to the solution is begin with at least one particle on the largest spike.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-100-particles.eps}
    \caption{The PSO algorithm with default parameters and 100 particles}\label{fig:pso:100-particles}
\end{figure}

Figures~\ref{fig:pso:100-particles} and~\ref{fig:pso:5-particles} shows the results with 100 and 5 particles respectively.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-5-particles.eps}
    \caption{The PSO algorithm with default parameters and 5 particles}\label{fig:pso:5-particles}
\end{figure}

Observe from \autoref{fig:pso:100-particles} that the swarm appears densest at the peak and troughs of the first spike.
When we animated the progress of the swarm, most of the particles seemed to accumulated \textit{between} spikes, which was surprising.

Notice also that the swarm is uniformly initialized throughout the domain, so the swarm mean is exactly that --- the mean of the $[0, 1]$ domain.

\paragraph{The Velocity Bounds $[v_{\min}, v_{\max}]$} The next parameter we chose to experiment with was the velocity bounds.
The velocity bounds restrict the maximum step a particle may take after its direction has been determined.
What we saw during animation of the swarm with small numbers of particles was that the swarm would clump around a single spike and never explore any of the other spikes.
Increasing the maximum allowable step size to allow stepping from one spike to another fixed the local behavior we saw.

This might be because particles were now free to overshoot their planned trajectories, and overshooting enabled the exploration of other regions of the search space.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-v01.eps}
    \caption{Results with the default velocity bounds $[-0.1, 0.1]$}\label{fig:pso-vmin-01-vmax-01}
\end{figure}

\autoref{fig:pso-vmin-01-vmax-01} shows the PSO results with the default bounds we chose of $[-0.1, 0.1]$.
From this, we can see that the swarm mean does not jump from spike to spike nearly enough to find the global optimum.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-v021.eps}
    \caption{Results with the velocity bounds $[-0.2, 0.2]$}\label{fig:pso-vmin-02-vmax-02}
\end{figure}

Enabling larger jumps in particle positions on each iteration readily fixed this problem.
\autoref{fig:pso-vmin-02-vmax-02} shows the results with bounds $[-0.2, 0.2]$.

We can see that the swarm jumps to the biggest spike quite early, and spends most of its time centered around the spike's peak.
This is the desired behavior.
Notice again, however, that the actual positions of the particles seemed to prefer the valleys \textit{between} the peaks, rather than the peaks themselves.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-v001-v02.eps}
    \caption{Results with the velocity bounds $[-0.01, 0.2]$}\label{fig:pso-vmin-001-vmax-02}
\end{figure}

We can bias the swarm to one direction or the other.
That is, we can use global information about the shape of the plot to push the swarm left or right.
\autoref{fig:pso-vmin-001-vmax-02} shows the results of using velocity bounds $[-0.01, 0.2]$, which
biases the swarm to the right --- which is the opposite of what we'd like.
We have, in effect, prevented the swarm from moving left at all.

It's difficult to see, but \autoref{fig:pso-vmin-001-vmax-02} also shows that the swarm is located to the right of the warm's best historical position.
This is expected from the plot of the swarm's mean and it's best location.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-v20-v001.eps}
    \caption{Results with the velocity bounds $[-0.2, 0.01]$}\label{fig:pso-vmin-02-vmax-001}
\end{figure}

\autoref{fig:pso-vmin-02-vmax-001} shows the results of the swarm biased in the opposite direction, with velocity bounds $[-0.2, 0.01]$.
We see an immediate pull to the left on the swarm centroid, and relatively little oscillation\footnote{This in itself is remarkable, and I'm sure would make perfect sense if one were to analyze the swarm's behavior as a system of differential equations. However, this author is suspicious of dynamical systems in general, and the mere thought of pursuing this unfortunate stray idea any farther is enough to cause heart palpitations.} after it corrects itself.

It is interesting that biasing the swarm to the right consistently forced the swarm's mean to be well above the solution, but biasing the swarm to the right forced the swarm's mean \textit{to} the solution, with little-to-no oscillation.

This time, as opposed to previous results, the particles have avoided the valleys in preference of the peaks.
This is remarkable, and has a perfectly reasonable explanation, but this is left as a simple exercise to the sophisticated reader.

\paragraph{The Acceleration Constants $AC_1$ and $AC_2$} Playing with both acceleration and velocity was revealing.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-sinusoids.eps}
    \caption{Them there's some sinusoids}\label{fig:pso:sinusoids}
\end{figure}

Different configurations of velocity and acceleration resulted in different oscillatory behavior.
This is completely unsurprising from a dynamical systems standpoints, where some configurations might be underdamped, overdamped, etc.

However, as mentioned, this author is suspicious of dynamical systems and refuses to make a claim other than ``Them there's some sinusoids''.
We were able to get results, and even some good results from the particle swarm optimization algorithm.
There's no need to perform anything so mathochistic as a dynamical systems analysis of the swarm behavior.

Note that much of the oscillatory behavior observed in this experimentation can be damped by using a swarm with more particles.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-high-vel-high-accel.eps}
    \caption{High velocity, high acceleration.}\label{fig:pso:high-vel-high-accel}
\end{figure}

Using high velocities and high accelerations means that the particles are jumping around much farther distances with every iteration.
The result is a less cohesive and more sparse swarm.
Yet a beneficial consequence is that the swarm explores more of the search space, resulting in more consistent results.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-high-vel-low-accel.eps}
    \caption{High velocity, low acceleration.}\label{fig:pso:high-vel-low-accel}
\end{figure}

Using high velocities with low acceleration results in a swarm that consistently overshoots are requires correction.
It is also necessary to run the algorithm for more iterations to settle down to a more reasonable solution.
We recommend avoiding this configuration.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-low-vel-high-accel.eps}
    \caption{Low velocity, high acceleration.}\label{fig:pso:low-vel-high-accel}
\end{figure}

Using low velocity with a high acceleration also has undesirable results.
This is the default configuration we used in previous analysis --- a default velocity bound of $[-0.1, 0.1]$ with acceleration constants $AC_1 = AC_2 = 2$.
We recommend avoiding this configuration as well.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-low-vel-low-accel.eps}
    \caption{Low velocity, low acceleration.}\label{fig:pso:low-vel-low-accel}
\end{figure}

Using low velocity with low acceleration is more oscillatory than with high velocities and low acceleration.
This is because using low accelerations results in a more cohesive swarm that moves together in a tighter packed bunch.
This can be beneficial --- the swarm can move faster throughout the fitness landscape --- yet it also produces more oscillation because the swarm overshoots and has to correct itself.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-tuned-vel-low-accel.eps}
    \caption{Tuned velocity, low acceleration.}\label{fig:pso:tuned-vel-low-accel}
\end{figure}

If we use the biased velocity limits to push the swarm to one side, we can see that it struggles to correct itself if the acceleration is lowered.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-tuned-vel-high-accel.eps}
    \caption{Tuned velocity, high acceleration.}\label{fig:pso:tuned-vel-high-accel}
\end{figure}

Our ultimate recommendation is to use global knowledge about the behavior of the function to push the swarm to one side or the other, yet to allow a high enough acceleration to correct any overshoots quickly.

This results in a stable swarm that does not move around much once it converges.

However, as \autoref{fig:pso:tuned-vel-bigger-domain} indicates, this only works if the optimum is to one side or the other of the feasible region.
In other cases, we must use equal left and right velocity biases.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/pso/pso-tuned-vel-bigger-domain.eps}
    \caption{Tuned velocity, bigger domain}\label{fig:pso:tuned-vel-bigger-domain}
\end{figure}

\subsection{Conclusion}
We found that simulated annealing readily beat both other methods without much tuning.
It took a considerable amount of thought and effort to tune the particle swarm optimization algorithm before it would consistently converge to the same solution over multiple runs.
However, once tuned, it performed just as well as simulated annealing.
\end{document}
