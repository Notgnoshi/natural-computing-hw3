\documentclass[12pt]{article}
\input{homework.sty}

\title{Homework 3}
\author{Austin Gill \\ Kali Regenold}

\begin{document}
\maketitle
\begingroup
\hypersetup{linkcolor=black}
\tableofcontents
\endgroup
\newpage

\section{Ant Clustering}

\subsection{Statement}

Use ant clustering to cluster uniformly distributed red and blue objects on a grid.
The grid should be $200 \times 200$ and there should be 100 each of red and blue objects.
Use 500 ants.

\subsection{Method}

The ant clustering algorithm is given by \autoref{alg:ant-clustering}, and is tunable by the definitions of $f$, $p_p$, $p_d$, and the paremeters $iters$, $ants$, $k_1$, and $k_2$.

\begin{algorithm}
    % \begin{noindent}
    \begin{algorithmic}
        \Function{ACA}{$iters$, $ants$, $k_1$, $k_2$}
            \State{Project items onto a 2D grid}
            \State{Randomly distribute ants in unoccupied (by another ant) locations}
            \State{$t \gets 1$}
            \While{$t < iters$}
                \For{$i \in \{1, \dots, ants\}$}\IComment{For each ant}
                    \State{Let $\vec x_i$ be the item $\vec x$ in ant $i$'s cell, if any}
                    \State{Compute $f(\vec x_i)$}
                    \IComment{$f$ is the perceived fraction of items near $\vec x_i$}
                    \If{ant $i$ is unloaded and cell contains an item}
                        \State{Compute pickup probability $p_p(\vec x_i)$}
                        \IComment{Tunable with parameter $k_1$}
                        \State{Pick up item $\vec x_i$ with probability $p_p(\vec x_i)$}
                    % The dumbest token for else if I've seen so far. Even worse then elif.
                    \ElsIf{ant $i$ is loaded and cell does not contain an item}
                        \State{Compute dropoff probability $p_d(\vec x_i)$}
                        \IComment{Tunable with parameter $k_2$}
                        \State{Drop off item $\vec x_i$ with probability $p_d(\vec x_i)$}
                    \EndIf{}
                    \State{Move ant $i$ to random unoccupied (by another ant) neighbor}
                \EndFor{}
                \State{$t \gets t + 1$}
            \EndWhile{}
            \State\Return{New locations of each item}
        \EndFunction{}
    \end{algorithmic}
    % \end{noindent}
    \caption{The standard Ant Clustering Algorithm (ACA)}\label{alg:ant-clustering}
\end{algorithm}

The pickup and dropoff probabilities are typically given by
\begin{align}
    p_p(\vec x_i) & = {\left(\frac{k_1}{k_1 + f(\vec x_i)}\right)}^2\label{eq:aca:pickup} \\
    p_d(\vec x_i) & = \begin{cases}
        2 f(\vec x_i) & \text{if} f(\vec x_i) < k_2 \\
        1             & \text{otherwise}
    \end{cases}\label{eq:aca:dropoff}
\end{align}
and the perceived fraction $f$ by
\begin{equation}
    f(\vec x_i) = \begin{cases}
        \displaystyle\frac{1}{s^2}\cdot\sum_{x_j \in \text{neighbors}}
        \left(1 - \frac{\mathrm{d}(\vec{x_i}, \vec{x_j})}{\alpha}\right) & \text{if } f > 0 \\
        0                                                                & \text{otherwise}
    \end{cases}\label{eq:aca:fraction}
\end{equation}
where the sum is over the square neighborhood of configurable size around the cell occupied by $\vec{x_i}$.
The parameter $\alpha$ is a tunable parameter that determines the scale of dissimilarity, and the distance metric $\mathrm d(\vec x, \vec y)$ is the Euclidean distance \textit{in the original, unprojected, space}.
For this problem though, we are starting with uniformly distributed points already in 2 dimensions.
\footnote{This is uncommon for ant clustering algorithms, but is suitable for a homework problem because the process of performing the projection from a possibly very high dimensional space to 2 dimensions is nontrivial.
    Especially so if the projection should retain certain characteristics of the original space.

    My current understanding though, is that even a randomish projection, or a naive application of a dimension reduction technique like PCA is fine, because the perceived fraction $f$ uses the distance metric $\mathrm{d}(\vec x, \vec y)$ in the original space, and it should be possible to project the found clusters in 2 dimensions back into the original space.}

However, it seems this definition is nonintuitively recursive, we believe the intent of \autoref{eq:aca:fraction} is that shown in \autoref{eq:aca:fraction-max}.

\begin{equation}
    f(\vec x_i) = \displaystyle\max\left(\frac{1}{s^2}\cdot\sum_{x_j \in \text{neighbors}}
    \left(1 - \frac{\mathrm{d}(\vec{x_i}, \vec{x_j})}{\alpha}\right), 0 \right)\label{eq:aca:fraction-max}
\end{equation}

Regardless, since the clustering is being performed in the same space as the objects, it is possible to use a better perceived fraction function.

\begin{equation}
    f(\vec x_i) = \frac{1}{s^2}\cdot\sum_{x_j \in \text{neighbors}}\bigg(\mathrm{type}(x_i) = \mathrm{type}(x_j)\bigg)\label{eq:aca:density}
\end{equation}

That is, to count the number of objects in the neighborhood (of configurable size) around $\vec x_i$ with the same type as $\vec x_i$.
Note that this density function is normalized by the size of the neighborhood as well.
This was important, because we wanted to play with as many tweakable parameters as possible --- the neighborhood size being one of those parameters.

\subsection{Implementation}
\todoinline{
    Comment on interesting portions of the implementation, providing source code.
    \begin{itemize}
        \item Show how the grid and ants are initialized, and mention that our decision to allow multiple colors complicated things.
        \item The fact we used Numba to JIT-compile our code to get an over $2\times$ speedup.
        \item Show the output of \mintinline{text}{./prob1 --help} and emphasize that we wanted to play with the tweakable parameters, in addition to the problem size, number of colors, etc.
        \item Mention the datastructures we ended up using and why (two layers of the grid, and a list of \mintinline{python}{Ant} objects.)
        \item Make note that the \mintinline{python}{update_position()} method still randomly teleports an ant to an unoccupied cell in its neighborhood (even if the radius is greater than 1) and why.

              We struggled getting one step updates to work, and I still don't understand why.
              Shrinking the kernel before the position update broke everything\dots

              Also mention that storing the ants in a list, and the objects in the grid caused problems.
              It would have been better to use a sparse representation where we could perform efficient lookup at a given position, but also easily iterate over the ants.
        \item Make note that when an ant picks up an object, it removes it from the grid, so it no longer impacts the perceived fraction density calculation from \autoref{eq:aca:density}.
    \end{itemize}
}

\subsection{Results}
\todoinline{
    Examine the impact of different tunable parameters.
    In no particular order --- as I think of them
    \begin{itemize}
        \item Neighborhood radius
        \item Periodic forced dropoff (and why --- one cluster sometimes formed, and every blue object got picked up, and would thus never get dropped off).
        \item The parameters $k_1$ and $k_2$, and how they, along with the neighborhood size, and the total number of iterations impacts the quality of the clusters.

              The Jupyter notebook \mintinline{text}{probabilities.ipynb} examines how $k_1$ and $k_2$ impact the pickup and dropoff probabilities, along with the neighborhood size.
        \item The number of colors
        \item The number of objects
        \item The size of the grid
        \item The number of ants (less than or greater than the total number of objects impacted cluster quality).
    \end{itemize}
}

\section{Particle Swarm Optimization}

\subsection{Statement}

Use particle swarm optimization to optimize the function
\begin{equation}
    f(x) = 2^{-2{\left(\frac{(x - 0.1)}{0.9}\right)}^2}{\big(\sin(5\pi x)\big)}^6\label{eq:pso:objective}
\end{equation}
and compare the results with those of simulated annealing from Homework 1.
\begin{figure}
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/prob1-function.eps}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/prob1-derivative.eps}
    \end{subfigure}
    \caption{The objective function~\ref{eq:pso:objective} and its derivative.}\label{fig:pso:objective}
\end{figure}
\autoref{eq:pso:objective} is plotted, along with its derivative, in \autoref{fig:pso:objective}.

\subsection{Method}

The standard particle swarm algorithm from the book is given in \autoref{alg:particle-swarm}.
The algorithm is tunable by the number of iterations, the acceleration constants $AC_1$ and $AC_2$, and the range of allowable velocities $[v_{\min}, v_{\max}]$.

\begin{algorithm}
    % \begin{noindent}
    \begin{algorithmic}
        \Function{PS}{$iters$, $AC_1$, $AC_2$, $v_{\min}$, $v_{\max}$}
            \State{Randomly initialize swarm $\vec{x_i} \in X$}
            \State{Randomly initialize swarm velocities $\Delta\vec{x_i}$}
            \IComment{$\Delta\vec{x_i} \in [v_{\min}, v_{\max}]$}
            \State{Let each $\vec{p_i} \gets \vec{x_i}$}
            \IComment{Best historical position for each particle}
            \State{$t \gets 1$}
            \While{$t < iters$}
                \For{$i \in \{1, \dots, particles\}$}
                    \IComment{For each particle}
                    \If{$f(\vec{x_i}) > f(\vec{p_i})$}
                        \IComment{Keep track of each particle's best position}
                        \State{$\vec{p_i} \gets \vec{x_i}$}
                    \EndIf{}
                    \State{$k \gets i$}\IComment{Arbitrary starting index}
                    \For{$j \in \{\text{neighbors of $\vec{x_i}$}\}$}
                        \IComment{Keep track of each particle's best neighbor}
                        \If{$f(\vec{p_j}) > g(\vec{p_k})$}
                            \State{$k \gets j$}
                        \EndIf{}
                    \EndFor{}
                    \State{Generate $\vec{\varphi_1}$ and $\vec{\varphi_2}$ uniformly}
                    \IComment{elementwise $\vec\varphi_i \in [0, AC]$}
                    % TODO: There's got to be a way to left justify the comment with the following
                    % line's indentation when it appears on an empty line...
                    \Statex\IComment{Linear combination of particle $i$'s historical best and neighbor's best}
                    \State{$\Delta\vec{x_i} \gets \Delta\vec{x_i} + \vec{\varphi_1} \otimes (\vec{p_i} - \vec{x_i}) + \vec{\varphi_2} \otimes (\vec{p_k} - \vec{x_i})$}
                    \State{$\Delta\vec{x_i} \in [v_{\min}, v_{\max}]$}
                    \IComment{Do not allow the velocities to explode, componentwise}
                    \State{$\vec{x_i} \gets \vec{x_i} + \Delta\vec{x_i}$}
                \EndFor{}
                \State{$t \gets t + 1$}
            \EndWhile{}
            \State\Return{$X$}
        \EndFunction{}
    \end{algorithmic}
    % \end{noindent}
    \caption{The standard Particle Swarm (PS) optimization algorithm}\label{alg:particle-swarm}
\end{algorithm}

The book states that the acceleration constants should equal 4.1. That is,
\[AC_1 + AC_2 = 4.1\]
with $AC_1 = AC_2 = 2.05$.
The acceleration constants are used to draw the vectors of weights $\vec{\varphi_1}$ and $\vec{\varphi_2}$ from a uniform distribution of $[0, AC_1]$ and $[0, AC_2]$ respectively.
Note that the $\otimes$ symbol is elementwise multiplication.

The update step
\begin{equation}
    \Delta\vec{x_i} \gets \Delta\vec{x_i} + \vec{\varphi_1} \otimes (\vec{p_i} - \vec{x_i}) + \vec{\varphi_2} \otimes (\vec{p_k} - \vec{x_i})\label{eq:pso:update}
\end{equation}
considers the direction towards the particle's best known position, and the best known position of its neighbors.
It updates its velocity as a randomly weighted linear combination of those directions.

There are several variants of \autoref{alg:particle-swarm} to consider.
One such variation is to consider, not the each best historical position of each particle's neighbors, but the best historical position of the entire swarm.
This difference is shown in \autoref{alg:particle-swarm-variant}.

\begin{algorithm}
    % \begin{noindent}
    \begin{algorithmic}
        \Function{PS-variant}{$iters$, $AC_1$, $AC_2$, $v_{\min}$, $v_{\max}$}
            \State{Randomly initialize swarm $\vec{x_i} \in X$}
            \State{Randomly initialize swarm velocities $\Delta\vec{x_i}$}
            \IComment{$\Delta\vec{x_i} \in [v_{\min}, v_{\max}]$}
            \State{Let each $\vec{p_i} \gets \vec{x_i}$}
            \IComment{Best historical position for each particle}
            \State{Let $\vec{p} \gets$ best $\vec{x_i} \in X$}
            \IComment{Swarm's best historical position}
            \State{$t \gets 1$}
            \While{$t < iters$}
                \For{$i \in \{1, \dots, particles\}$}
                    \IComment{For each particle}
                    \If{$f(\vec{x_i}) > f(\vec{p_i})$}
                        \IComment{Keep track of each particle's best position}
                        \State{$\vec{p_i} \gets \vec{x_i}$}
                    \EndIf{}
                    \If{$f(\vec{x_i}) > f(\vec{p})$}
                        \IComment{Update the swarm's best position}
                        \State{$\vec{p} \gets \vec{x_i}$}
                    \EndIf{}
                    \State{Generate $\vec{\varphi_1}$ and $\vec{\varphi_2}$ uniformly}
                    \IComment{elementwise $\vec\varphi_i \in [0, AC]$}
                    % TODO: There's got to be a way to left justify the comment with the following
                    % line's indentation when it appears on an empty line...
                    \Statex\IComment{Linear combination of particle $i$'s historical best and
                        swarm's best}
                    \State{$\Delta\vec{x_i} \gets \Delta\vec{x_i} + \vec{\varphi_1} \otimes (\vec{p_i} - \vec{x_i}) + \vec{\varphi_2} \otimes (\vec{p} - \vec{x_i})$}
                    \State{$\Delta\vec{x_i} \in [v_{\min}, v_{\max}]$}
                    \IComment{Do not allow the velocities to explode, componentwise}
                    \State{$\vec{x_i} \gets \vec{x_i} + \Delta\vec{x_i}$}
                \EndFor{}
                \State{$t \gets t + 1$}
            \EndWhile{}
            \State\Return{$X$}
        \EndFunction{}
    \end{algorithmic}
    % \end{noindent}
    \caption{A variant Particle Swarm optimization algorithm}\label{alg:particle-swarm-variant}
\end{algorithm}

We implemented \autoref{alg:particle-swarm-variant} to solve the given problem.

\subsection{Implementation}

The implementation of a single iteration of \autoref{alg:particle-swarm-variant} is straightforward.

\begin{minted}{python}
    def update(self, func):
        """Perform one iteration of optimization."""
        for i, particle in enumerate(self.particles):
            if func(x) > func(self.history[i]):
                self.history[i] = particle
            if func(x) > func(self.best):
                self.best = particle

            phi1 = np.random.uniform(low=0, high=self.AC1, size=1)
            phi2 = np.random.uniform(low=0, high=self.AC2, size=1)

            self.velocities[i] += phi1 * (self.history[i] - particle) + phi2 * (self.best - particle)
            # Clip the velocities.
            self.velocities[i] = min(self.vmax, max(self.vmin, self.velocities[i]))
            self.particles[i] += self.velocities[i]
            # Clip the positions.
            self.particles[i] = min(self.xmax, max(self.xmin, self.particles[i]))
\end{minted}

It \textit{should} be straightforward to parallelize this to update each particle at once, or in batches.
However, to do so correctly, the swarm's best known position, \mintinline{python}{self.best} should be guarded with a mutex.
Further, multithreading in Python often yields little-to-no improvement in runtime, because every single object in Python is guarded by the Global Interpreter Lock (GIL).
Threading is still useful in networking or file operation contexts, threading is eschewed for performing CPU-bound work in favor of multiprocessing.
The difficulty in using multiple processes for this task is that they have no shared memory, which increases the amount of communication overhead to a point we are unlikely to see a big performance benefit for this particular problem.

Not to mention that extremely small numbers of particles were still effective in optimizing \autoref{eq:pso:objective} due to the size of the feasible region.

Note that this implementation is strictly one-dimensional.
Additional work must be done to optimize functions of multiple variables.
To work in more than one dimension,
\begin{itemize}
    \item $\varphi_1$ and $\varphi_2$ should have the same dimension as each particle.
    \item Each particle velocity should be a tuple of velocities --- one for each dimension.
    \item The particle velocity and position clipping should be done componentwise.
\end{itemize}

Running the PSO algorithm for multiple iterations is equally straightforward.

\begin{minted}{python}
    def optimize(self, func, iters, animate=False):
        """Optimize the given function for `iters` iterations."""
        b = np.argmax(func(self.particles))
        self.best = self.particles[b]

        for i in range(iters):
            self.update(func)

            if animate and i % 5 == 0:
                self.plot(func, blocking=False)

        return self.best
\end{minted}

As in the first problem, we implemented our solution in such as way as to allow us to play with a large number of tweakable parameters.
All of the parameters are adjustable via commandline arguments shown below.

\begin{minted}{text}
    $ ./prob2.py --help
    usage: prob2.py [-h] [--xmin XMIN] [--xmax XMAX] [--ac1 AC1] [--ac2 AC2]
                    [--vmin VMIN] [--vmax VMAX] [--particles PARTICLES]
                    [--iterations ITERATIONS] [--animate] [--headless]

    Optimize a function with a particle swarm.

    optional arguments:
    -h, --help              show this help message and exit
    --xmin XMIN             The lower domain boundary.
    --xmax XMAX             The upper domain boundary.
    --ac1 AC1               Acceleration constant for the particle history component.
    --ac2 AC2               Acceleration constant for the swarm history component.
    --vmin VMIN             The particle velocity lower bound.
    --vmax VMAX             The particle velocity upper bound.
    --particles PARTICLES, -p PARTICLES
                            The number of particles in the swarm.
    --iterations ITERATIONS, -i ITERATIONS
                            The number of iterations to use.
    --animate               Animate the swarm's progress.
    --headless              A headless mode for profiling.
\end{minted}

Note that considerable more work would need to be done, as above, to make this wrapper script handle multivariate objective functions.
The difficulty lies in specifying the feasible region to optimize over, using commandline arguments.

Setting the objective function to optimize is less easy to do from the commandline,\footnote{In a secure fashion. It's possible to use \mintinline{python}{eval()} or \mintinline{python}{ast.literal_eval()}, but both of these methods make this author queasy.}
so the \mintinline{python}{func(x)} function in the `prob2.py' script must be edited.

\subsection{Results}
\subsubsection{Hill Climbing}
Recall\footnote{Or let us make the recollection for you.} from Homework 1 that hill climbing struggles with ``spiky'' functions.
\autoref{fig:pso:hill-climbing-results} shows the results from several independent runs of the hill climbing algorithm on the objective function \autoref{eq:pso:objective}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/prob1-hill-climbing-results.eps}
    \caption{Results from three successive runs of the hill climbing algorithm.}\label{fig:pso:hill-climbing-results}
\end{figure}

Running the randomly-initialized hill climbing algorithm multiple times in parallel and taking the best result works okay, as long as the number of parallel runs is proportional to the density of the spikes in the feasible region.
\autoref{fig:pso:hill-climbing-parallel} shows the aggregated results of several parallel runs of the iterated hill climbing algorithm.

From this we can immediately see that there is quite a bit in the variance of multiple runs.
The success of the hill climbing algorithm depends entirely on the its random initialization.

\begin{figure}[h]
    \centering
    \includegraphics{figures/prob1-hill-climbing-solution.eps}
    \caption{Results from multiple runs of the hill climbing algorithm in parallel.}\label{fig:pso:hill-climbing-parallel}
\end{figure}

\subsubsection{Simulated Annealing}
Recall also that simulated annealing worked \textit{much} better.
\autoref{fig:pso:simulated-annealing-results} shows a steady peak-to-peak trend from the simulated annealing algorithm, because it accepts enough random solutions to explore non-local space, but over time cools down enough to settle to a reasonable solution.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/prob1-simulated-annealing-results.eps}
    \caption{Results from three successive runs of the simulated annealing algorithm.}\label{fig:pso:simulated-annealing-results}
\end{figure}

\autoref{fig:pso:simulated-annealing-parallel} is much more illuminating; not only does the simulated annealing algorithm not find non-global solutions, each iterated run settled down to exactly the same solution.

\begin{figure}[h]
    \centering
    \includegraphics{figures/prob1-simulated-annealing-solutions.eps}
    \caption{Results from multiple runs of the simulated annealing algorithm in parallel.}\label{fig:pso:simulated-annealing-parallel}
\end{figure}

\subsubsection{Particle Swarm}
\todoinline{
    \begin{itemize}
        \item Play with tweakable parameters.
        \item Mention that simulated annealing beats out this method on this particular function.
        \item Mention that it might have been better to implement \autoref{alg:particle-swarm} instead of \autoref{alg:particle-swarm-variant}, because this method easily finds the peak of a given spike, but using the variant method pulls to strongly towards the spike, so the swarm never explores other regions of the search space.
    \end{itemize}
}

\end{document}
